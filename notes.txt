regression
- regression works by predicting value of one variable based
on another variable x

- goal is to obtain a relationship between the annual salary and car purchasing amount (using y = mx+b)
- once the coefficient 'm' and 'b' are obtained, we are able to build the regression model
- will later use this model to predict car purchase amount based on annual salary

artificial neural networks
- similar to the brain, there are 100 million of neurons communicating with each other and help us see, think
and hear
- in artificial networks, we are trying to create something similar (neural networks)
 

 cat           input>>    loop until cat (corrected output) (brain  (deviated outputs>>  error>>)
(correct label: cat)

single neuron model
-neuron collects signals from input (dendrites) and proccess information in the nuclues than outputs in the axon
-a bunch of inputs x1, x2, x3 multipled by w1, w2, w2. bias signal that shifts the function up and down. then apply a generative
function f to create a trained model
y = f(x1w1 + x2w2 + x3w3 + b)
-if the output is positive, the output is 1, if it's negative, the output is 0


network training
- backpropogation is a method used ot train artical network neurons by calculating gradient needed to update network weights
- adjust the weight of neurons by calculating the gradient of the loss function

- Phase one: 1.foward propogation 2. calculate error
~ propogate foward through the network to generate output value
~ propogate output activations back through the network using training pattern target inorder to generate delta
(difference between targeted and actual ouput values)

- Phase two: 3. back propogation 4.weight update
~ calculate weight gradientratio of weight gradients is subtract from weight
~ ratio influences the speed and quality of learning called the learning rate.
~ the greater the ratio the faster the neuron train. lower ratio, more accurate the training is

two neuron model: matrix representation
- combine two singular neuron model
- f(W * P + b)

random notes
- 'X'to represent inputs and 'y' for output
- remove unecessary x-values or columns
- we need to scale the data before training the model
- no overfitting, cannot train the model with specific examples
- train with generalization
-when network is goign down, it's learning something
-remove independent variables that are not correlated to the dependent variable
-when training a data it is best if we scale it first. This helps the machine learning algorithims
-usually scale 0 to 1, if it was on a regular scale, the model will focus more on larger values and ignore the smaller ones
- we split the data into training data and testing data to prevent overfitting. We don't want the model to do well on the training set but 
do bad on the testing data.
- testing set is used to test the model's unseen data-
- generalization, the ability to accurately predict outcome
-train: input, y-train: output, epochs: number of iterations, batch_size: number of samples per gradient update, verbose: controls level of detail printed,
validation_split: fraction of the training data to be used as validation data, basically a reward system forn the model
-training loss shows how well the model is doing on the training data (seen data)
-validation loss shows how well the model is doing on the unseen dating (testing data)

